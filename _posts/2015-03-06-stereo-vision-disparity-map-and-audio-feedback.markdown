---
layout: post
title:  "Yuliya: Stereo Vision: Disparity Map and Audio Feedback"
date:   2015-03-06 12:18:33
categories: jekyll update
---



### Stereo Vision: Disparity Map and Audio Feedback
-------------

#### Creating a Disparity Map: OpenCV

In my previous approach I have mentioned using OpenCV to create a disparity map given two pictures. The most complicated part was figuring out the parameters that are supposed to be passed to the algorithm such as thresholds, minimum possible disparity value that influences shifting images, etc. 

I have decided to start with recommended parameters and refine them as needed. It turned out, I still had to make some estimations and educated guesses, but the overall result turned out quite good. For sample images I used a couple of pictures downloaded from the web.

My first roadblock was OpenCV itself. The documentation could be more detailed, which would have saved me quite a lot of time. This is especially true with the parameters as they are the most important component influencing the disparity map directly - the resulting map could be either good or contain a bunch of rather meaningless speckles. Overcoming this roadblock involved setting parameters close to recommended defaults. One thing to be noted here though that this is not guaranteed to be a final setup because the data that Chris will get from his part (that is, the settings) might change it. 

After the parameters were figured out, the next thing to do was to analyze the disparity map resulted. SGBM returns back a single grayscale image, which is just a two-dimensional array. For a proof of concept I have temporarily rejected projecting a polar grid on the map and detecting the ground plane, as these just help to narrow down the parts of the map of the image to be processed (it disregards far away objects, tree branches, etc). Since no ground plane was being detected, the algorithm instead takes into consideration a base disparity of the map. Base disparity is a most frequent value encountered on the map. The deviation threshold that determines whether the pixel should be considered or disregarded is set to 1.5 of base disparity. 

After base disparity has been calculated, the algorithm parses the image using the threshold, looking at the beginning of the region where the deviation from the base disparity exceeds deviation threshold, and the end of the region. If the region size exceeds dimension threshold (this is done to eliminate noise and artifacts produced by the algorithm), then the algorithm classifies it into one of the regions: left, front, or right. As I am not using a polar grid, my simplification was splitting the image in three sectors: where left and right sectors each occupy 1/4 of the image, and 1/2 of the image is devoted to the front sector. The algorithm classifies detected obstacle into a respective sector and marks this sector as having an obstacle. 

This approach is not flawless by all means. One of the problems comes from the disparity map itself, as it gets quite difficult to analyze it with lighting and shadows, as those seem to affect disparity of the objects. I also feel that the base disparity value is something that should be used very carefully in these settings, and there should be a better way to identify obstacles. 

#### Audio Feedback: Settings

After the regions were marked with respect to the obstacles belonging to them, it was time to use audio feedback. For the audio, I am using PyAudio, which allows me to create sounds without reading from files. The principle that I am using is pretty much the same as the authors of the stereo vision paper have used. For an obstacle in front I am using frequency of 440 Hz with both channels, for an obstacle on the left or on the right I am using frequency of 750 Hz with left or right channel. Should there be obstacles both on the left and on the right, the signal corresponding to the obstacles will be played using both channels simultaneously. 

#### Conclusions

There is quite a lot left to do. We should connect the part that Chris wrote with this sample code to see how it behaves with actual pictures. If maps generated by the phone would be of a significantly worse quality, altering parameters and also possibly object detection should be reconsidered. If connection succeeds though, all that would be left to do will be to project a polar grid on the map, detect a ground floor, and consider only the objects that belong to the ground floor, which would then lead to better performance. 